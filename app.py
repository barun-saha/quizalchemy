"""
QuizAlchemy: Transmute text into knowledge

A quiz generation application using Google ADK and Streamlit.
"""
import json
import logging
import mimetypes
import random
import re
import sqlite3
import warnings
from typing import List, Optional

import litellm
import streamlit as st
from markitdown import MarkItDown
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from google.adk.agents import Agent
from google.adk.models.lite_llm import LiteLlm
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
from google.genai import types


FILE_URL = 'https://web.stanford.edu/class/cs102/lectureslides/ClassificationSlides.pdf'
APP_NAME = 'quizalchemy'
MODEL_GEMINI = 'gemini/gemini-2.0-flash-lite'
DIFFICULTY_LEVELS = ['easy', 'medium', 'hard']

QUESTION_BANK_PROMPT = '''
You are an expert tutor. Given the text below, create a question bank having 10--20 questions
and their answers. The questions provide multiple choices where only one choice is correct.
The `answer_key` field will contain the list index (0-based) of the correct answer in the `choices` 
list. In addition, create questions with three levels of difficulties: easy, medium, and hard.
About 40% of the questions should be easy, 30% medium, and 30% hard.
IMPORTANT: The questions and answers must be based solely and only on the provided text
and must be factually correct. Create them in a way that promotes critical thinking.
Also, create the questions and answers in the same language as the input text.

An illustrative example:
{{
    "questions": [
        {{
            "question": "What is the capital of India?",
            "choices": ["New Delhi", "Mumbai", "Kolkata", "Chennai"],
            "answer_key": 0,
            "difficulty": "easy"
        }}
    ]
}}

# Text
{text}
'''


load_dotenv()
logging.basicConfig(level=logging.ERROR)
warnings.filterwarnings('ignore')

llm = LiteLlm(model=MODEL_GEMINI)


class QuestionAnswer(BaseModel):
    """
    Represents a question and its multiple choice answers.
    """
    id: Optional[int] = Field(
        None,
        description='The question number, auto-generated by DB. Skip it.'
    )
    question: str = Field(description='The question text.')
    choices: list[str] = Field(description='A list of multiple choice answers for the question.')
    answer_key: int = Field(description='The list index (0-based) of the correct answer.')
    difficulty: str = Field(description='easy, medium, or hard.')

    def to_sql_tuple(self):
        """Convert model to a tuple for SQLite insertion."""
        # Note: 'id' is excluded here as it's typically auto-incremented by the DB
        return (
            self.question, json.dumps(self.choices), self.answer_key, self.difficulty
        )

    @classmethod
    def from_sql_row(cls, row):
        """Convert SQLite row to Pydantic model."""
        return cls(
            id=row[0], # The DB's auto-generated primary key
            question=row[1],
            choices=json.loads(row[2]),
            answer_key=row[3],
            difficulty=row[4]
        )

class QuestionBank(BaseModel):
    """
    Represents a collection of questions associated with a specific document.
    """
    questions: list[QuestionAnswer] = Field(default_factory=list)

    def save_to_db(self, connection: sqlite3.Connection):
        """Save question bank and its questions to SQLite."""
        cursor = connection.cursor()

        for question in self.questions:
            cursor.execute(
                '''
                    INSERT INTO questions (question, choices, answer_key, difficulty)
                    VALUES (?, ?, ?, ?)
                ''',
                question.to_sql_tuple()
            )
        connection.commit()
        print(f'Saved {len(self.questions)} questions to DB.')

    @classmethod
    def load_from_db(cls, connection: sqlite3.Connection):
        """Load question bank from SQLite."""
        cursor = connection.cursor()
        cursor.execute('SELECT * FROM questions')
        rows = cursor.fetchall()
        if not rows:
            return None

        questions = [QuestionAnswer.from_sql_row(row) for row in rows]
        print(f'Loaded {len(questions)} questions from DB.')
        return cls(questions=questions)

    def filter_by_difficulty(self, difficulty: str) -> List[QuestionAnswer]:
        """Filter questions by difficulty."""
        return [q for q in self.questions if q.difficulty == difficulty]

    def get_random_questions(self, num_questions: int = 5) -> List[QuestionAnswer]:
        """Get a random selection of questions."""
        return random.sample(self.questions, min(num_questions, len(self.questions)))

    def get_random_questions_by_difficulty(
            self,
            difficulty: str,
            num_questions: int = 5
    ) -> List[QuestionAnswer]:
        """Get random questions filtered by difficulty."""
        filtered = self.filter_by_difficulty(difficulty)
        return random.sample(filtered, min(num_questions, len(filtered)))


# Tool to extract text from various file formats as Markdown
def extract_as_markdown(
        url_or_file_path: str,
        scrub_links: bool = True,
        max_length: int = 64_000
) -> str:
    """
    Extract the contents from HTML files (.html), PDF files (.pdf), Word Documents (.docx),
    and Excel spreadsheets (.xlsx) as Markdown text. No other file type is supported.
    The text can be used for analysis with LLMs. Input can be a URL or a local file path.
    This tool can directly work with URLs, so no need to download the files separately.
    NOTE: The output returned by this function can be long and may involve lots of quote marks.

    Args:
        url_or_file_path: URL or Path to a .html, .pdf, .docx, or .xlsx file.
        scrub_links: Defaults to `True`, which removes all links from the extracted Markdown text.
         Set it to `False` if you want to retain the links in the text.
        max_length: Limit the output to the first `max_length` characters. Defaults to 64,000.

    Returns:
        The content of the file in Markdown format.
    """
    print('🛠 extract_as_markdown() called')
    md = MarkItDown(enable_plugins=False)

    try:
        result = md.convert(url_or_file_path.strip()).text_content

        if mimetypes.guess_type(url_or_file_path)[0] == 'application/pdf':
            # Handling (cid:NNN) occurrences specific to some PDF extractions
            cid_pattern = re.compile(r'\(cid:(\d+)\)')
            matches = set(cid_pattern.findall(result))
            for cid_num in matches:
                cid_str = f'(cid:{cid_num})'
                result = result.replace(cid_str, chr(int(cid_num) + 29))

        if scrub_links:
            # Remove Markdown links [text](url)
            result = re.sub(r'\[([^\]]+)\]\((https?:\/\/[^\)]+)\)', r'\1', result)

        if max_length is not None:
            result = result[:max_length]

        return result
    except Exception as e:
        # Log the full exception for debugging, return error message to agent
        logging.error('Error extracting markdown from %s: %s', url_or_file_path, str(e))
        return f'Error extracting text: {str(e)}'


# Tool to create a question bank from a text document
async def create_question_bank(text: str) -> QuestionBank:
    """
    Create a question bank (i.e., a list of questions) based on the provided text.

    Args:
        text: The text content from which to generate the question bank.

    Returns:
        A QuestionBank object containing a list of questions.
    """
    print('🛠 create_question_bank() called')

    if not text or len(text.strip()) < 50: # Basic check for meaningful text
        print('CRITICAL ERROR: Input text to create_question_bank is empty or too short.')
        return QuestionBank(questions=[])

    print(f'Showing the first 100 characters of input text: {text[:100]}...')

    response = await litellm.acompletion(
        model=MODEL_GEMINI,
        messages=[{'role': 'user', 'content': QUESTION_BANK_PROMPT.format(text=text)}],
        response_format=QuestionBank
    )
    response = response.choices[0].message.content
    # print(f'{response=}')
    qbank: QuestionBank = QuestionBank.model_validate_json(response)
    print(f'Number of questions from LLM Output: {len(qbank.questions)}')

    # Database interaction with raw SQLite3
    connection = get_db_connection()
    try:
        qbank.save_to_db(connection) # Use the Pydantic model's save_to_db method
    except Exception as db_error:
        print(f'ERROR: Database save failed: {db_error}')
        raise

    return qbank


# Tool to create a quiz with a specified number of questions
def create_quiz(
        num_items: int = 5,
        easy: float = 0.4,
        medium: float = 0.3,
) -> List[QuestionAnswer]:
    """
    Create a quiz with a specified number of questions.
    The `easy` and `medium` parameters determine the proportions of easy and medium questions.
    Default values are used unless otherwise specified.
    The proportions of hard questions will be `1 - easy - medium`.

    Args:
        num_items: The number of questions to include in the quiz.
        easy: Proportion of easy questions (default is 0.4).
        medium: Proportion of medium questions (default is 0.3).

    Returns:
        A list of selected questions for the quiz.
    """
    print('🛠 create_quiz() called')
    # conn = get_db_connection()

    # try:
    qbank = QuestionBank.load_from_db(get_db_connection())
    if not qbank or not qbank.questions:
        print('No question bank found or it contains no questions!')
        return []

    easy_questions = qbank.filter_by_difficulty(DIFFICULTY_LEVELS[0])
    medium_questions = qbank.filter_by_difficulty(DIFFICULTY_LEVELS[1])
    hard_questions = qbank.filter_by_difficulty(DIFFICULTY_LEVELS[2])
    print(f'{len(easy_questions)=}, {len(medium_questions)=}, {len(hard_questions)=}')

    # Determine the number of questions per difficulty
    num_easy = int(num_items * easy)
    num_medium = int(num_items * medium)
    num_hard = num_items - num_easy - num_medium
    print(f'{num_easy=}, {num_medium=}, {num_hard=}')

    # Randomly select questions while handling cases where there aren't enough
    easy_questions = random.sample(easy_questions, min(num_easy, len(easy_questions)))
    medium_questions = random.sample(medium_questions, min(num_medium, len(medium_questions)))
    hard_questions = random.sample(hard_questions, min(num_hard, len(hard_questions)))

    # Combine and shuffle the final quiz
    quiz_questions = easy_questions + medium_questions + hard_questions
    random.shuffle(quiz_questions)

    print(f'Generated quiz with {len(quiz_questions)} questions')
    # print the actual questions for debugging
    for i, q in enumerate(quiz_questions):
        print(f'  {i+1}. Q: {q.question} (Difficulty: {q.difficulty})')
    # except Exception as e:
    #     print(f'Error creating quiz: {e}')
    #     return []

    return quiz_questions


def get_db_connection() -> sqlite3.Connection:
    """Return the connection to the in-memory SQLite database."""
    return st.session_state.db_conn


def create_db_tables() -> sqlite3.Connection | None:
    """
    Create a SQLite database and table for questions using raw SQL.
    This function will be called once at the beginning of the script.

    Returns:
        The connection object to the SQLite database or `None` if an error occurs.
    """
    connection = None
    try:
        connection = sqlite3.connect(':memory:', check_same_thread=False)
        cursor = connection.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS questions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                question TEXT NOT NULL,
                choices TEXT NOT NULL, -- Stored as JSON string
                answer_key INTEGER NOT NULL,
                difficulty TEXT NOT NULL
            )
        ''')
        connection.commit()
        print('Database tables created successfully.')
    except sqlite3.Error as e:
        print(f'Error creating database tables: {e}')

    return connection


def evaluate_answer(question: QuestionAnswer, answer: str):
    pass


async def create_agents() -> Agent:
    """
    Create and return the root agent for the application.

    Returns:
        An instance of `Agent` configured for quiz generation.
    """
    ingestion_agent = Agent(
        name='DataIngestionAgent',
        model=llm,
        description=(
            'Ingests data from files or websites (URLs), based on which question-answer pairs'
            ' (question bank) are generated and stored in a database. The database can be used'
            ' by others to create quizzes.'
        ),
        instruction=(
            'You are the data ingestion agent supporting quiz generation. Your role is two-fold.'
            ' First, You help with data ingestion by extracting the contents of files. You can'
            ' work with local file paths and URLs. Second, based on the ingested contents, you also'
            ' generate a set of question-answer pairs (question bank) with different difficult'
            ' levels and save them in a database.'
        ),
        tools=[extract_as_markdown, create_question_bank],
    )
    logging.info('Agent `%s` created using model `%s`', ingestion_agent.name, MODEL_GEMINI)

    quizmaster_agent = Agent(
        name='QuizMasterAgent',
        model=llm,
        description=(
            'Generates quizzes based on the question bank (database) and evaluates answers.'
        ),
        instruction=(
            'You are the quiz master agent. Your role is to create quizzes based on the'
            ' question bank (existing database) already created by DataIngestionAgent. To generate'
            ' a quiz, you select questions from the question bank based on difficulty levels and'
            ' the number of items requested, if any (`create_quiz` tool). In addition, you'
            ' also evaluate the answers provided by the user against the correct answers'
        ),
        tools=[create_quiz, evaluate_answer],
    )
    logging.info(
        'Agent `%s` created using model `%s`', quizmaster_agent.name, {MODEL_GEMINI}
    )

    coordinator_agent = Agent(
        name='CoordinatorAgent',
        model=llm,
        description=(
            'Coordinates between the data ingestion and quiz master agents.'
        ),
        instruction=(
            'You are the coordinator agent. You play a critical role in identifying which task'
            ' should be delegated to which agent reliably. If a query provides/relates to a data'
            ' source, either a file path or URL, you typically need to delegate to the'
            ' DataIngestionAgent. On the other hand, if a query relates to creating or fetching'
            ' a quiz, you should delegate to the QuizMasterAgent.'
        ),
        sub_agents=[ingestion_agent, quizmaster_agent],
    )
    logging.info(
        'Root Agent `%s` created using model `%s`', coordinator_agent.name, MODEL_GEMINI
    )

    return coordinator_agent


async def call_agent_async(query: str, runner, user_id: str, session_id: str):
    """
    Send a query to the agent and print the final response.

    Args:
        query: The user's query string.
        runner: The Runner instance to execute the agent.
        user_id: User identifier for the session.
        session_id: Session identifier for the conversation.
    """
    print(f'\n🔍 User Query: {query}')

    content = types.Content(role='user', parts=[types.Part(text=query)])
    final_response_text = 'Agent did not produce a final response.'

    async for event in runner.run_async(
            user_id=user_id,
            session_id=session_id,
            new_message=content
    ):
        print(
            f'  🎉 Author: {event.author}, Type: {type(event).__name__},'
            f' Final: {event.is_final_response()}, Content: {event.content}'
        )

        if event.is_final_response():
            if event.content and event.content.parts:
                final_response_text = event.content.parts[0].text
            elif event.actions and event.actions.escalate:
                final_response_text = (
                    f"Agent escalated: {event.error_message or 'No specific message.'}"
                )
            break

    print(f'🖺 Agent Response: {final_response_text}')


async def run_conversation():
    """
    Run a conversation with the agent, creating a session and executing the agent.
    This function initializes the session, creates the agent, and runs the conversation loop.
    """
    # Session Management
    session_service = InMemorySessionService()
    user_id = 'default_user'
    session_id = user_id

    await session_service.create_session(
        app_name=APP_NAME,
        user_id=user_id,
        session_id=session_id
    )
    print(f'ADK session created: {APP_NAME=}, {user_id=}, {session_id=}')

    # Runner setup
    runner = Runner(
        agent=await create_agents(),
        app_name=APP_NAME,
        session_service=session_service
    )
    print(f'Runner created for agent `{runner.agent.name}`')

    queries = [
        f'Create Question Bank from {FILE_URL}',
        'Create a quiz with 5 questions',
    ]

    for query in queries:
        await call_agent_async(
            query,
            runner=runner,
            user_id=user_id,
            session_id=session_id
        )


# Set up DB connection in session state
if 'db_conn' not in st.session_state:
    st.session_state.db_conn = create_db_tables()

# Use the connection
db_connection = st.session_state.db_conn
db_cursor = db_connection.cursor()

st.title("🏗️ Streamlit Session-Scoped SQLite Demo")

# Show messages
db_cursor.execute('SELECT * FROM questions')
rows = db_cursor.fetchall()
st.write("Messages from the database:")
for row in rows:
    st.write(f"{row[0]} says: {row[1]}")

# # Allow user to add a message
# new_msg = st.text_input("Add a message")
# if st.button("Save message"):
#     cur.execute("INSERT INTO messages VALUES (?, ?)", ("You", new_msg))
#     conn.commit()
#     st.experimental_rerun()


if __name__ == '__main__':
    import asyncio
    asyncio.run(run_conversation())
